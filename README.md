# DLSpecialization_DeepLearningIA
Contains Solutions and Notes for the [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by Andrew NG on Coursera.

## Course 1: [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning/home/)

- [Week 1](https://www.coursera.org/learn/neural-networks-deep-learning/home/week/1)

    - What is a Neural Network (NN) ? 
    - Why is deep learning taking off ? 
    - Supervised learning with NN
    - Geoffrey Hinton interview. 

- [Week 2](https://www.coursera.org/learn/neural-networks-deep-learning/home/week/2)

    - Logistic Regression NN
    - Binary Classification
    - Gradient descent
    - Computational graph 
    - Python and vectorization
    - Pieter Abbeel interview.

- [Week 3](https://www.coursera.org/learn/neural-networks-deep-learning/home/week/3)

    - NN representation
    - Computing a NN output
    - Vectorizing across multiple examples
    - Activation Functions 
    - Gradient descent for NN
    - Back propagation computation and intuition 
    - Random weights initialization
    - Ian Goodfellow interview. 

- [Week4](https://www.coursera.org/learn/neural-networks-deep-learning/home/week/4)

    - Deep L-layer NN
    - Deep representations
    - Forward and backward propagation 
    - Parameters vs Hyperparameters
    - Getting your matrix dimensions right
    - What does NN have to do with the brain ? 

#### [Certificate Of Completion](https://coursera.org/share/9198bf9e5641668612752b5cd17be8a2)



## Course 2: [Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization](https://www.coursera.org/learn/deep-neural-network/home)


- [Week 1](https://www.coursera.org/learn/deep-neural-network/home/week/1)

    - Train / Dev / Test sets 
    - Bias and Variance
    - Basic Recipe for machine learning (Idea -> Implementation -> Experiment )
    - Regularization
        - Dropout  
        - Weight decay
    - Normalizing inputs
    - Vanishing/Exploding gradients
    - Weight initialization for DNN
    - Gradient checking

- [Week 2](https://www.coursera.org/learn/deep-neural-network/home/week/2)

    - Mini-batch gradient descent 
    - Exponentially weighted averages and bias correction
    - Gradient descent with momentum
    - RMSprop
    - Adam optimization algorithm inputs
    - Learning rate decay
    - The problem of local minima

- [Week 3](https://www.coursera.org/learn/deep-neural-network/home/week/3)

    - Tuning process
    - Batch normalization
    - Softmax regression
    - DeepLearning frameworks
    - Gradient tape

#### [Certificate Of Completion](https://coursera.org/share/4fbdf56b633deffa6166b342350d4219)


## Course 3: [Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-network/home)


- [Week 1](https://www.coursera.org/learn/deep-neural-network/home/week/1)

    - Computer vision 
    - Edge detection filters
    - Pooling layers
    - Strided convolutions
    - Why convolutions? 
    - CNN convolutions

- [Week 2](https://www.coursera.org/learn/deep-neural-network/home/week/2)

    - Residual NN
    - Inception NN
    - MobileNet
    - EfficientNet
    - Transfer learning 
    - Data agumentation
    - Pooling layers
    - Strided convolutions
    - Why convolutions? 
    - CNN convolutions

- [Week 3](https://www.coursera.org/learn/deep-neural-network/home/week/2)

    - Object localization
    - Bounding box predictions
    - Intersection over union
    - Anchor boxes
    - YOLO algorithm
    - Semantic segmentation U-Net
    - U-Net architecture intuition 
    
#### [Certificate Of Completion](https://coursera.org/share/3845e95e0fc6228c7aa621b4fb44092a)


## Course 4: [Recurrent Neural Networks](https://www.coursera.org/learn/sequence-models/home)

- [Week 1](https://www.coursera.org/learn/deep-neural-network/home/week/1)

    - Sequence models
    - Recurrent Neural Network model
    - Back propagation through time
    - Types of RNNs
    - Language Models and Sequence Generation 
    - Vanishing gradient with RNNs
    - Gated Recurrent Unit (GRU)
    - Long Short Term Memory (LSTM)
    - Bidirectional RNN
    - Deep RNNs 

- [Week 2](https://www.coursera.org/learn/deep-neural-network/home/week/2)

    - Word Representation. 
    - Using Word Embeddings. 
    - Properties of Word Embeddings. 
    - Embedding Matrix. 
    - Word2Vec
    - Negative Sampling
    - GloVe Word Vectors
    - Sentiment Classification 
    - Debiasing word embeddings

- [Week 3](https://www.coursera.org/learn/deep-neural-network/home/week/3)

    - Basic Models
    - Beam search
    - Refinements to beam search. 
    - Error analysis in beam search.
    - Bleu Score
    - Attention Model intuition
    - Attention Model.
    - Speach Recognition
    - Trigger word detection. 

